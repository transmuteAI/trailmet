{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sjvQBGDZuGt0",
        "outputId": "c9170ec0-c5a3-48c8-8e2f-9d3b76bc4ae0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G9bXDQ3t0re",
        "outputId": "cd4d9df1-9923-46c0-9cc5-e764e04a88f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZPe9nmatZgL",
        "outputId": "68a1bb4d-f088-4116-ed1a-fa7023cfa026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/trailmet\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/trailmet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4esoRo_5tZgm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from trailmet.models import ModelsFactory\n",
        "from trailmet.datasets.classification import DatasetFactory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L9p805IftZgr"
      },
      "outputs": [],
      "source": [
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "isk71WP6tZgz"
      },
      "outputs": [],
      "source": [
        "root = '/content/drive/MyDrive/trailmet/experiments/ReActNet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FfJnPV08tZg6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open(os.path.join(root,\"reactnet_cifar100.yaml\"),'r') as stream:\n",
        "    data_loaded = yaml.safe_load(stream)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfTg8XNqtZg8",
        "outputId": "5012a0c0-b09b-438b-89ca-dcdec50e6b88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GENERAL': {'BACKBONE': 'resnet18', 'DATASET': 'CIFAR100'},\n",
              " 'ReActNet1_ARGS': {'batch_size': 128,\n",
              "  'epochs': 1,\n",
              "  'label_smooth': 0.1,\n",
              "  'learning_rate': 0.0025,\n",
              "  'momentum': 0.9,\n",
              "  'weight_deacy': '1e-5'},\n",
              " 'ReActNet2_ARGS': {'batch_size': 128,\n",
              "  'epochs': 1,\n",
              "  'label_smooth': 0.1,\n",
              "  'learning_rate': 0.0025,\n",
              "  'momentum': 0.9,\n",
              "  'weight_deacy': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GbyZRrXZtZg_"
      },
      "outputs": [],
      "source": [
        "model = ModelsFactory.create_model('resnet18', 10, False, insize=32)\n",
        "teacher = ModelsFactory.create_model('resnet101', 10, False, insize=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BzVUHex7tZhD"
      },
      "outputs": [],
      "source": [
        "from trailmet.datasets.classification import DatasetFactory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymo3cF-wtZhH",
        "outputId": "03b18835-4c60-4e51-ec23-1baf6d23336a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data_dir’: File exists\n"
          ]
        }
      ],
      "source": [
        "mkdir data_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S6L-rh_QtZhL"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "val_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "[transforms.ToTensor()])\n",
        "\n",
        "transforms1 = {\n",
        "    'train': train_transform, \n",
        "    'val': val_transform, \n",
        "    'test': test_transform}\n",
        "def train_target_transform(label):\n",
        "    return label\n",
        "\n",
        "def val_target_transform(label):\n",
        "    return label\n",
        "\n",
        "def test_target_transform(label):\n",
        "    return label\n",
        "\n",
        "target_transforms = {\n",
        "    'train': None, \n",
        "    'val': None, \n",
        "    'test': None}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoBfW8z9tZhP",
        "outputId": "99c61390-d02d-4786-baa0-f85ae66f0c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_dataset = DatasetFactory.create_dataset(name = 'CIFAR10', \n",
        "                                        root = 'data_dir',\n",
        "                                        split_types = ['train', 'val', 'test'],\n",
        "                                        val_fraction = 0.2,\n",
        "                                        transform = transforms1,\n",
        "                                        target_transform = target_transforms\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BR5Q76x6tZhR"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['train_dataset'], batch_size=64, \n",
        "        sampler=cifar_dataset['train_sampler'],\n",
        "        num_workers=0\n",
        "    )\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['val_dataset'], batch_size=64, \n",
        "        sampler=cifar_dataset['val_sampler'],\n",
        "        num_workers=0\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        cifar_dataset['test_dataset'], batch_size=64, \n",
        "        sampler=cifar_dataset['test_sampler'],\n",
        "        num_workers=0\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q49t7FO6tZhV"
      },
      "outputs": [],
      "source": [
        "from trailmet.algorithms.binarize.ReActNet import ReActNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4N9b3m_mtZhY"
      },
      "outputs": [],
      "source": [
        "a = ReActNet(teacher,model, {'train': train_loader, 'val': val_loader, 'test': test_loader}, **data_loaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV2C7kIXtZhZ",
        "outputId": "b7358978-150d-4c4a-fb00-7ed0caf36d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-1 Training with activations binarized for 1 epochs\n",
            "\n",
            "EPOCH-0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "100%|██████████| 157/157 [00:04<00:00, 35.66it/s, acc=0.0999, loss=2.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Train Loss-2.535806939315796\n",
            "Top-1 Train Accuracy-9.695\n",
            "Top-5 Train Accuracy-50.085\n",
            "Validation Accuracy-0.0999\n",
            "Validation Loss-2.3412274372805455\n",
            "Step-2 Training with both activations and weights binarized for 1 epochs\n",
            "EPOCH-0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:07<00:00, 20.82it/s, acc=0.0948, loss=2.61]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Train Loss-3.0345276432037354\n",
            "Top-1 Train Accuracy-9.795\n",
            "Top-5 Train Accuracy-50.2775\n",
            "Validation Accuracy-0.0948\n",
            "Validation Loss-2.6053057779931716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fin = a.compress_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xVW2pWyHu6dH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.2 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f5e9b3cd15ac88d9bd193ea7bab8ca00cfa51bd651fd2d7c541a11e62e4d7d9c"
      }
    },
    "colab": {
      "name": "trailmet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}