{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b08dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../../\")\n",
    "#sys.path.append(\"workspace/code/Nahush26/Tmet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25b05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from trailmet.trailmet.datasets.classification import DatasetFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9d81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trailmet.trailmet.algorithms.prune.network_slimming_train import NetworkSlimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e629fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/workspace/code/Nahush26/TrAIL/trailmet/experiments/Prune'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f20a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform=transforms.Compose([\n",
    "                                      transforms.Pad(4),\n",
    "                                      transforms.RandomCrop(32),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                  ])\n",
    "val_transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                              ])\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d957779b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms1 = {\n",
    "    'train': train_transform, \n",
    "    'val': val_transform, \n",
    "    'test': test_transform}\n",
    "def train_target_transform(label):\n",
    "    return label\n",
    "\n",
    "def val_target_transform(label):\n",
    "    return label\n",
    "\n",
    "def test_target_transform(label):\n",
    "    return label\n",
    "\n",
    "target_transforms = {\n",
    "    'train': None, \n",
    "    'val': None, \n",
    "    'test': None}\n",
    "cifar_dataset = DatasetFactory.create_dataset(name = 'CIFAR10', \n",
    "                                        root = data_root,\n",
    "                                        split_types = ['train', 'val', 'test'],\n",
    "                                        val_fraction = 0.2,\n",
    "                                        transform = transforms1,\n",
    "                                        target_transform = target_transforms\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26255a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        cifar_dataset['train_dataset'], batch_size=64, \n",
    "        sampler=cifar_dataset['train_sampler'],\n",
    "        num_workers=0\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        cifar_dataset['val_dataset'], batch_size=64, \n",
    "        sampler=cifar_dataset['val_sampler'],\n",
    "        num_workers=0\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        cifar_dataset['test_dataset'], batch_size=64, \n",
    "        sampler=cifar_dataset['test_sampler'],\n",
    "        num_workers=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4c0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self,train_loader = train_loader , val_loader = val_loader):\n",
    "        self.DATA = 'cifar10'\n",
    "        #self.epochs = 256\n",
    "        #self.lr = 0.001\n",
    "        #self.momentum = 0.9\n",
    "        #self.weight_decay = 0\n",
    "        self.TRAIN_LOADER = train_loader\n",
    "        self.TEST_LOADER = val_loader\n",
    "        self.OPTIMIZER_NAME = \"SGD\"\n",
    "        self.FINE_TUNE = True\n",
    "        self.SPARSITY_REG = False\n",
    "        self.PATH = './pruned_checkpoint.pth.tar'\n",
    "        self.SAVE ='./pruned_checkpoint.pth.tar'\n",
    "        self.MODEL = 'model_best.pth.tar'\n",
    "    \n",
    "        #self.label_smooth = 0.1\n",
    "        #self.num_workers = 4\n",
    "        #self.dataset = 'cifar10'  #valid options are cifar100, cifar10 and tiny-imagenet\n",
    "        #self.num_classes = 10 #10 for CIFAR10 // 100 for CIFAR100 // 200 for Tiny ImageNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd40550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = CFG()\n",
    "args = args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ee6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = NetworkSlimming(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3e24a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd423a66940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.args.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(3, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(21, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(50, 78, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(78, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(78, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (11): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(45, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(90, 85, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (18): BatchNorm2d(85, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(85, 87, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (21): BatchNorm2d(87, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(87, 65, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (24): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(65, 188, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (28): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(188, 188, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (31): BatchNorm2d(188, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(188, 194, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (34): BatchNorm2d(194, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(194, 177, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (37): BatchNorm2d(177, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(177, 147, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (41): BatchNorm2d(147, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(147, 134, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (44): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(134, 142, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (47): BatchNorm2d(142, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(142, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (50): BatchNorm2d(510, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=510, out_features=10, bias=True)\n",
      ")\n",
      "0\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.450590\n",
      "Train Epoch: 0 [6400/50000 (16.0%)]\tLoss: 0.817403\n",
      "Train Epoch: 0 [12800/50000 (32.0%)]\tLoss: 0.644408\n"
     ]
    }
   ],
   "source": [
    "model1 = check.fine_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f35c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab71c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5d499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
