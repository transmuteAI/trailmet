{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms as transforms\n",
    "from torchvision import datasets as datasets\n",
    "torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_imagenet_data(data_path: str = '', input_size: int = 224, batch_size: int = 64, workers: int = 4,\n",
    "                        dist_sample: bool = False):\n",
    "    print('==> Using Imagenet Dataset')\n",
    "\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    #torchvision.set_image_backend('accimage')\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        valdir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    if dist_sample:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        val_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=workers, pin_memory=True, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,batch_size=batch_size, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True, sampler=val_sampler)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using Imagenet Dataset\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataloaders = {'train':[], 'val':[]}\n",
    "dataloaders['train'], dataloaders['val'] = build_imagenet_data(data_path='/workspace/code/Akash/ImageNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from trailmet.models import resnet\n",
    "from trailmet.algorithms.quantize.brecq import BRECQ\n",
    "from trailmet.algorithms.quantize.quantize import BaseQuantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "cnn = resnet.get_resnet_model('resnet50', 1000, 224, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45f4fa6b9b847b7a948ccad8d9ccc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(80.53082833429231, 95.22303150693048, 0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test full precision model\n",
    "bq = BaseQuantization()\n",
    "bq.test(model=cnn, dataloader=dataloaders['val'], device=torch.device('cuda:7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Setting the first and the last layer to 8-bit\n",
      "==> Initializing weight quantization parameters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac649b13b4774a40adb2c93982e5721f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized accuracy before brecq: (55.30476949069481, 77.8277628010717, 0.0)\n",
      "==> Starting weight calibration\n",
      "Ignore reconstruction of layer conv1\n",
      "Reconstruction for block 0\n",
      "Total loss:\t483.689 (rec:0.644, round:483.046)\tb=13.25\tcount=1000\n",
      "Total loss:\t199.292 (rec:0.959, round:198.333)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t509.780 (rec:40.379, round:469.401)\tb=13.25\tcount=1000\n",
      "Total loss:\t254.552 (rec:37.905, round:216.647)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t489.750 (rec:42.663, round:447.087)\tb=13.25\tcount=1000\n",
      "Total loss:\t222.848 (rec:45.072, round:177.776)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t2423.465 (rec:53.310, round:2370.155)\tb=13.25\tcount=1000\n",
      "Total loss:\t964.340 (rec:54.799, round:909.542)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t1784.104 (rec:65.987, round:1718.117)\tb=13.25\tcount=1000\n",
      "Total loss:\t705.271 (rec:62.737, round:642.534)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t1730.266 (rec:62.453, round:1667.812)\tb=13.25\tcount=1000\n",
      "Total loss:\t647.936 (rec:68.672, round:579.264)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t1717.029 (rec:64.733, round:1652.296)\tb=13.25\tcount=1000\n",
      "Total loss:\t621.296 (rec:62.083, round:559.213)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t9100.884 (rec:79.949, round:9020.936)\tb=13.25\tcount=1000\n",
      "Total loss:\t3268.855 (rec:87.997, round:3180.858)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t6737.598 (rec:92.696, round:6644.901)\tb=13.25\tcount=1000\n",
      "Total loss:\t2383.212 (rec:93.342, round:2289.870)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t6597.418 (rec:94.655, round:6502.763)\tb=13.25\tcount=1000\n",
      "Total loss:\t2218.584 (rec:96.477, round:2122.106)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t6663.128 (rec:93.480, round:6569.649)\tb=13.25\tcount=1000\n",
      "Total loss:\t2311.036 (rec:96.312, round:2214.723)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 4\n",
      "Total loss:\t6624.605 (rec:90.966, round:6533.640)\tb=13.25\tcount=1000\n",
      "Total loss:\t2267.580 (rec:91.079, round:2176.501)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 5\n",
      "Total loss:\t6476.241 (rec:73.114, round:6403.127)\tb=13.25\tcount=1000\n",
      "Total loss:\t2101.043 (rec:77.540, round:2023.504)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t37723.527 (rec:226.098, round:37497.430)\tb=13.25\tcount=1000\n",
      "Total loss:\t14768.767 (rec:211.116, round:14557.650)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t27417.434 (rec:134.422, round:27283.012)\tb=13.25\tcount=1000\n",
      "Total loss:\t10120.478 (rec:127.697, round:9992.780)\tb=2.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t26752.529 (rec:58.369, round:26694.160)\tb=13.25\tcount=1000\n",
      "Total loss:\t9204.546 (rec:54.544, round:9150.002)\tb=2.00\tcount=2000\n",
      "Reconstruction for layer fc\n",
      "Total loss:\t10456.123 (rec:6.751, round:10449.372)\tb=13.25\tcount=1000\n",
      "Total loss:\t2415.106 (rec:7.796, round:2407.310)\tb=2.00\tcount=2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90775c6089764e348f7e00657c53c0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight quantization accuracy: (80.07952153334884, 95.056438122251, 0.0)\n",
      "Ignore reconstruction of layer conv1\n",
      "Reconstruction for block 0\n",
      "Total loss:\t73.976 (rec:73.976, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t72.456 (rec:72.456, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t62.294 (rec:62.294, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t61.987 (rec:61.987, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t23.575 (rec:23.575, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t23.473 (rec:23.473, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t89.514 (rec:89.514, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t92.396 (rec:92.396, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t35.816 (rec:35.816, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t36.481 (rec:36.481, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t17.994 (rec:17.994, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t26.201 (rec:26.201, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t9.724 (rec:9.724, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t9.844 (rec:9.844, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t55.644 (rec:55.644, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t64.112 (rec:64.112, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t27.418 (rec:27.418, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t27.929 (rec:27.929, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t13.698 (rec:13.698, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t12.806 (rec:12.806, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 3\n",
      "Total loss:\t15.495 (rec:15.495, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t16.074 (rec:16.074, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 4\n",
      "Total loss:\t13.783 (rec:13.783, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t12.862 (rec:12.862, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 5\n",
      "Total loss:\t6.729 (rec:6.729, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t6.629 (rec:6.629, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 0\n",
      "Total loss:\t93.077 (rec:93.077, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t101.052 (rec:101.052, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 1\n",
      "Total loss:\t39.584 (rec:39.584, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t37.288 (rec:37.288, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for block 2\n",
      "Total loss:\t29.225 (rec:29.225, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t31.139 (rec:31.139, round:0.000)\tb=0.00\tcount=2000\n",
      "Reconstruction for layer fc\n",
      "Total loss:\t0.193 (rec:0.193, round:0.000)\tb=0.00\tcount=1000\n",
      "Total loss:\t0.320 (rec:0.320, round:0.000)\tb=0.00\tcount=2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef79053a6ab46ca8b15071d04873be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>TqdmHBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "  0%|          | 0/754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full quantization (W4A8) accuracy: (80.08159381451594, 94.97354687556664, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# quantize model\n",
    "kwargs = {\n",
    "    'W_BITS':4, \n",
    "    'A_BITS':8, \n",
    "    'CHANNEL_WISE':True, \n",
    "    'ACT_QUANT':True, \n",
    "    'NUM_SAMPLES':1024, \n",
    "    'ITERS_W':2000, \n",
    "    'ITERS_A':2000, \n",
    "    'CALIB_BS':64, \n",
    "    'GPU_ID':7,\n",
    "    }\n",
    "qnn = BRECQ(cnn, dataloaders, **kwargs)\n",
    "qnn.compress_model()\n",
    "\n",
    "# increase iterations from 2000 to 20000 to achieve full optimization potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 15 19:23:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   212W / 300W |  31301MiB / 32510MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   199W / 300W |    670MiB / 32510MiB |     93%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    56W / 300W |   3576MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   48C    P0   188W / 300W |    670MiB / 32510MiB |     94%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    55W / 300W |   1422MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    41W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    54W / 300W |   9212MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    54W / 300W |   4306MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
