{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:2'\n",
    "DATA_PATH = '/workspace/code/Akash/ImageNet'\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms as transforms\n",
    "from torchvision import datasets as datasets\n",
    "sys.path.append(\"../../\")\n",
    "torch.cuda.set_device(int(DEVICE[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_imagenet_data(data_path: str = '', input_size: int = 224, batch_size: int = 128, workers: int = 4,\n",
    "                        dist_sample: bool = False):\n",
    "\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    #torchvision.set_image_backend('accimage')\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        valdir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    if dist_sample:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        val_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=workers, pin_memory=True, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,batch_size=2*batch_size, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True, sampler=val_sampler)\n",
    "    print('==> Using Imagenet Dataset')\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using Imagenet Dataset\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = build_imagenet_data(data_path=DATA_PATH, batch_size=BATCH_SIZE)\n",
    "dataloaders = {'train' : trainloader,'val' : valloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from trailmet.models import resnet\n",
    "from trailmet.algorithms.quantize.lapq import LAPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "cnn = resnet.get_resnet_model('resnet50', 1000, 224, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 377/377 [02:54<00:00,  2.16it/s, acc1=80.6, acc5=95.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80.57368279009346, 95.23171871600164)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "from trailmet.algorithms.algorithms import BaseAlgorithm\n",
    "BaseAlgorithm().test(model=cnn, dataloader=dataloaders['val'], device=torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using seed: 42 and device: cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 377/377 [05:22<00:00,  1.17it/s, acc1=79.6, acc5=94.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Quantization (W8A8) accuracy before LAPQ: 79.5825 | 94.7696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:59<00:00, 17.93s/it, loss=1.47, p_val=4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> using p intr : 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 377/377 [05:29<00:00,  1.15it/s, acc1=78.6, acc5=94.5, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Quantization (W8A8) accuracy before Optimization: 78.5940 | 94.4722\n",
      "==> Loss after LpNorm Quantization: 1.4926\n",
      "==> Starting Powell Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [13:17<00:00,  7.97s/it, curr_loss=1.47, min_loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Layer-wise Scales :\n",
      " [ 1.08419957  0.66990249  3.11701354 23.20393628  2.29466365  5.01725674\n",
      "  0.88589263  2.71039438 13.73392868  1.71813965  1.08358109  4.9899826\n",
      " 13.23023605  0.99806833  0.23113976  1.4500705  21.30290604  1.43157232\n",
      "  0.60028028  0.52513981  2.32189894 11.73145962  0.63942772  0.90473968\n",
      "  2.75055075 11.44539928  0.41463852  0.57082433  1.68877172 18.08906937\n",
      "  0.8276599   0.3363277   1.09530067 23.4847126   0.85443014  0.61002809\n",
      "  0.82910395  1.98843825 14.02664661  0.42910361  0.84472984  2.2858727\n",
      " 13.89950275  0.38925895  0.81029177  1.74581611 27.58506393  0.51952708\n",
      "  0.53956091  1.79805577 29.66171265  0.35620919  0.51285464  1.15933418\n",
      " 18.59424782  0.53665894  0.21605009  1.12820017 20.25750923  0.93485618\n",
      "  0.27749813  0.37784204  1.60273576 15.03666401  0.41211852  0.68783522]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 377/377 [04:09<00:00,  1.51it/s, acc1=79.3, acc5=94.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Full quantization (W8A8) accuracy: (79.28890613788636, 94.85007988805796)\n"
     ]
    }
   ],
   "source": [
    "# quantize model\n",
    "kwargs = {\n",
    "    'W_BITS':8, \n",
    "    'A_BITS':8, \n",
    "    'ACT_QUANT':True,\n",
    "    'CALIB_BATCHES':1024//BATCH_SIZE, \n",
    "    'MAX_ITER':100,\n",
    "    'MAX_FEV':100,\n",
    "    'VERBOSE':True,\n",
    "    'PRINT_FREQ':20,\n",
    "    'GPU_ID':int(DEVICE[-1]),\n",
    "    'SEED':42\n",
    "    }\n",
    "qnn = LAPQ(cnn, dataloaders, **kwargs)\n",
    "qnn.compress_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 377/377 [04:12<00:00,  1.49it/s, acc1=79.3, acc5=94.9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79.28890613788636, 94.85007988805796)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test quantized model\n",
    "from trailmet.algorithms.algorithms import BaseAlgorithm\n",
    "BaseAlgorithm().test(model=qnn.model, dataloader=dataloaders['val'], device=torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
